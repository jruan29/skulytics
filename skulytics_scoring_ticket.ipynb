{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "f08439e8-c0f7-4fc2-a09d-36c98e20e42e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SHOW CATALOGS LIKE 'skulytics_dev';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "5281a5be-f118-4ed2-9585-f51e97302335",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SHOW SCHEMAS IN skulytics_dev;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4dd3d26f-e080-4b74-93a7-8116b0ded526",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT *\n",
    "FROM skulytics_dev.default.dim_product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43184198-b796-4ce0-8e6c-86c9be7b0e98",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1764696768894}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT *\n",
    "FROM skulytics_dev.default.fact_retail_summary_tbl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec86d4c8-73fd-4390-bc3e-f9aadc62032d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# CELL 1: Imports and Global Helper Functions\n",
    "# These functions are foundational for all subsequent scoring logic.\n",
    "# -------------------------------------------------------------------------\n",
    "import json\n",
    "import re\n",
    "from math import floor, ceil\n",
    "\n",
    "# PySpark Imports required for table creation and persistence (Cell 9)\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "from pyspark.sql import Row, SparkSession \n",
    "\n",
    "def clean_and_normalize(text):\n",
    "    \"\"\"Simple cleaning for keyword matching and word count.\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    # Remove punctuation, convert to lowercase, and replace newlines/tabs with spaces\n",
    "    text = re.sub(r'[^\\w\\s]', '', text).lower()\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "def word_count(text):\n",
    "    \"\"\"Counts words based on whitespace separation.\"\"\"\n",
    "    return len(text.split()) if text else 0\n",
    "\n",
    "print(\"Cell 1: Imports and Helper Functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f722daa-c3ce-4a17-a48f-9993f3d11278",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# CELL 2: Configuration and Business Rules\n",
    "# Defines all retailer-specific thresholds, keywords, and benefit lexicons.\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "RETAILER_RULES = {\n",
    "    'amazon': {\n",
    "        'title': {'ideal_min': 80, 'ideal_max': 150, 'acceptable_min': 50, 'acceptable_max': 200},\n",
    "        'description': {'ideal_min_words': 150, 'ideal_max_words': 300, 'acceptable_min_words': 80, 'acceptable_max_words': 400, 'too_short_max': 25, 'way_too_long_min': 400},\n",
    "        'image_count': {'ideal': 6, 'good_min': 4, 'acceptable_min': 2}\n",
    "    },\n",
    "    'walmart': {\n",
    "        'title': {'ideal_min': 50, 'ideal_max': 75, 'acceptable_min': 40, 'acceptable_max': 100},\n",
    "        'description': {'ideal_min_words': 50, 'ideal_max_words': 150, 'acceptable_min_words': 25, 'acceptable_max_words': 250, 'too_short_max': 25, 'way_too_long_min': 250},\n",
    "        'image_count': {'ideal': 4, 'good_min': 3, 'acceptable_min': 2}\n",
    "    },\n",
    "    'target': {\n",
    "        'title': {'ideal_min': 21, 'ideal_max': 100, 'acceptable_min': 1, 'acceptable_max': 150},\n",
    "        'description': {'ideal_min_words': 50, 'ideal_max_words': 200, 'acceptable_min_words': 25, 'acceptable_max_words': 300, 'too_short_max': 25, 'way_too_long_min': 300},\n",
    "        'image_count': {'ideal': 4, 'good_min': 4, 'acceptable_min': 2} \n",
    "    }\n",
    "}\n",
    "\n",
    "CATEGORY_KEYWORDS = {\n",
    "    ('Appliances', 'Coffee', 'amazon'): [\"Coffee Maker\", \"programmable\", \"thermal carafe\", \"12-cup\", \"auto shut-off\", \"brew strength\"],\n",
    "    ('Appliances', 'Coffee', 'walmart'): [\"coffee maker\", \"programmable\", \"stainless steel\", \"carafe\", \"auto shut-off\"],\n",
    "    ('Snacks', 'Granola', 'amazon'): [\"granola bars\", \"organic\", \"oats\", \"honey\", \"snack\", \"gluten-free\"],\n",
    "    ('Snacks', 'Granola', 'walmart'): [\"granola bars\", \"organic\", \"oats\", \"honey\", \"snack\", \"gluten-free\"],\n",
    "}\n",
    "\n",
    "PRIMARY_CATEGORY_KEYWORDS = {\n",
    "    ('Appliances', 'Coffee'): \"coffee maker\",\n",
    "    ('Snacks', 'Granola'): \"granola bars\",\n",
    "    ('Beauty', 'Skincare'): \"night cream\",\n",
    "}\n",
    "\n",
    "BENEFIT_VERBS = [\n",
    "    \"helps\", \"supports\", \"improves\", \"prevents\", \"protects\", \"ideal for\",\n",
    "    \"perfect for\", \"enhances\", \"reduces\", \"increases\"\n",
    "]\n",
    "\n",
    "print(\"Cell 2: Configuration loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b028b13-7b63-46e6-b843-c93910b853b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# CELL 3: Mock Data Setup (Explicitly defined input tables)\n",
    "# This setup clearly defines the four data sources needed for the scoring engine.\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "MOCK_CONTENT_TBL = [\n",
    "    {\n",
    "        'product_key': 'SKU015',\n",
    "        'retailer_key': 'amazon',\n",
    "        'title_text': \"Coffee Maker 12 Cup\",\n",
    "        'description_text': \"Makes coffee. 12 cup capacity. Brews fast.\",\n",
    "        'bullets_json': json.dumps([\"12-cup capacity\"]),\n",
    "        'attributes_json': json.dumps({\"capacity_cups\": 12, \"color\": \"Black\", \"material\": \"Stainless Steel\"}),\n",
    "        'image_count': 2\n",
    "    },\n",
    "    {\n",
    "        'product_key': 'SKU001',\n",
    "        'retailer_key': 'amazon',\n",
    "        'title_text': \"BrewMaster Supreme 12-Cup Thermal Programmable Coffee Maker with Stainless Steel Accents\",\n",
    "        'description_text': \"The BrewMaster Supreme helps you start your day right. This machine supports fast brewing and enhances the flavor of your favorite beans. It protects against spills and prevents over-extraction, ideal for busy mornings. It reduces waste and increases your enjoyment, making it perfect for every kitchen.\",\n",
    "        'bullets_json': json.dumps([f\"Feature {i}\" for i in range(1, 9)]),\n",
    "        'attributes_json': json.dumps({\"capacity_cups\": 12, \"color\": \"Stainless Steel\", \"model\": \"Supreme\"}),\n",
    "        'image_count': 7\n",
    "    },\n",
    "    {\n",
    "        'product_key': 'SKU003',\n",
    "        'retailer_key': 'walmart',\n",
    "        'title_text': \"Organic Oats N' Honey Granola Bars (20 Count)\",\n",
    "        'description_text': \"A delicious and healthy snack.\",\n",
    "        'bullets_json': json.dumps([\"Organic ingredients\", \"Gluten-free\", \"Oats and Honey\"]),\n",
    "        'attributes_json': json.dumps({\"flavor\": \"Honey\", \"count\": 20, \"Organic\": \"organic\"}),\n",
    "        'image_count': 3\n",
    "    }\n",
    "]\n",
    "\n",
    "# Simulates fact_retail_summary_tbl\n",
    "MOCK_FACT_RETAIL_SUMMARY_TBL = [\n",
    "    {'product_key': 'SKU015', 'retailer_key': 'amazon', 'avg_rating': 3.5, 'review_count': 15, 'prior_month_review_count': 14},\n",
    "    {'product_key': 'SKU001', 'retailer_key': 'amazon', 'avg_rating': 4.7, 'review_count': 250, 'prior_month_review_count': 230},\n",
    "    {'product_key': 'SKU003', 'retailer_key': 'walmart', 'avg_rating': 4.1, 'review_count': 80, 'prior_month_review_count': 85}\n",
    "]\n",
    "\n",
    "# Simulates dim_brand\n",
    "MOCK_DIM_BRAND = [\n",
    "    {'product_key': 'SKU015', 'brand_name': 'BrewMaster'},\n",
    "    {'product_key': 'SKU001', 'brand_name': 'BrewMaster'},\n",
    "    {'product_key': 'SKU003', 'brand_name': 'Oatfield'},\n",
    "]\n",
    "\n",
    "# Simulates dim_product\n",
    "MOCK_DIM_PRODUCT = [\n",
    "    {'product_key': 'SKU015', 'major': 'Appliances', 'minor': 'Coffee'},\n",
    "    {'product_key': 'SKU001', 'major': 'Appliances', 'minor': 'Coffee'},\n",
    "    {'product_key': 'SKU003', 'major': 'Snacks', 'minor': 'Granola'},\n",
    "]\n",
    "\n",
    "print(\"Cell 3: Mock Data initialized explicitly for all four tables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02bd848d-be3d-4fd4-9a15-c1c2cd198926",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# CELL 4: Dimension 1: Title Score Logic (titlescore)\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "def score_title(title_text, retailer_key, brand_name, category, attributes_json):\n",
    "    \"\"\"Dimension 1: Title Score (titlescore)\"\"\"\n",
    "    title_text = title_text or \"\"\n",
    "    rules = RETAILER_RULES.get(retailer_key, {})['title']\n",
    "    \n",
    "    # 1. Length compliance (0–40 pts)\n",
    "    length = len(title_text)\n",
    "    length_pts = 40 if rules['ideal_min'] <= length <= rules['ideal_max'] else (20 if rules['acceptable_min'] <= length <= rules['acceptable_max'] else 0)\n",
    "    \n",
    "    # 2. Brand presence (0–20 pts)\n",
    "    brand_pts = 20 if brand_name and clean_and_normalize(brand_name) in clean_and_normalize(title_text) else 0\n",
    "    \n",
    "    # 3. Product category/type keyword (0–20 pts)\n",
    "    category_pts = 0\n",
    "    primary_keyword = PRIMARY_CATEGORY_KEYWORDS.get(category)\n",
    "    if primary_keyword and primary_keyword in clean_and_normalize(title_text):\n",
    "        category_pts = 20\n",
    "    \n",
    "    # 4. Key attributes present (0–20 pts)\n",
    "    attribute_pts = 0\n",
    "    matched_attributes_count = 0\n",
    "    missing_attributes_list = []\n",
    "    \n",
    "    clean_title = clean_and_normalize(title_text)\n",
    "    \n",
    "    try:\n",
    "        attributes = json.loads(attributes_json)\n",
    "        for attr_key, attr_value in attributes.items():\n",
    "            \n",
    "            search_key = \"\"\n",
    "            \n",
    "            # --- FIX: Handle Boolean/True/False Attributes by searching for the KEY ---\n",
    "            if isinstance(attr_value, bool) or str(attr_value).lower() in ['true', 'false']:\n",
    "                # For boolean attributes (e.g., 'organic'), search for the key 'organic'\n",
    "                search_key = attr_key.lower().replace('_', ' ')\n",
    "            else:\n",
    "                # For standard attributes (e.g., color, capacity), search for the value '12' or 'black'\n",
    "                search_key = str(attr_value).lower().replace('-', ' ')\n",
    "            # --- END FIX ---\n",
    "            \n",
    "            if search_key and search_key in clean_title:\n",
    "                matched_attributes_count += 1\n",
    "            else:\n",
    "                missing_attributes_list.append(attr_key)\n",
    "                \n",
    "        if matched_attributes_count >= 2:\n",
    "            attribute_pts = 20\n",
    "        elif matched_attributes_count == 1:\n",
    "            attribute_pts = 10\n",
    "        \n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Warning: Failed to parse attributes_json for {retailer_key}.\")\n",
    "        \n",
    "    titlescore = min(100, length_pts + brand_pts + category_pts + attribute_pts)\n",
    "    \n",
    "    # Diagnostics\n",
    "    diag = {\n",
    "        'title_length': length,\n",
    "        'title_length_pts': length_pts,\n",
    "        'title_brand_pts': brand_pts,\n",
    "        'title_category_pts': category_pts,\n",
    "        'title_attribute_pts': attribute_pts,\n",
    "        'missing_attributes_list': \", \".join(missing_attributes_list)\n",
    "    }\n",
    "    \n",
    "    return titlescore, diag\n",
    "\n",
    "print(\"Cell 4: Title Score logic defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c965cbb4-e935-4a0c-86a1-f617e5f8dcf3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# CELL 5: Dimension 2: Description Score Logic (descscore)\n",
    "# Measures word count compliance, bullet point structure, and benefit language.\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "def score_description(description_text, bullets_json, retailer_key):\n",
    "    \"\"\"Dimension 2: Description Score (descscore)\"\"\"\n",
    "    description_text = description_text or \"\"\n",
    "    rules = RETAILER_RULES.get(retailer_key, {})['description']\n",
    "    \n",
    "    # 1. Word count (0–40 pts)\n",
    "    word_ct = word_count(description_text)\n",
    "    length_pts = 0\n",
    "    if rules['ideal_min_words'] <= word_ct <= rules['ideal_max_words']:\n",
    "        length_pts = 40\n",
    "    elif rules['acceptable_min_words'] <= word_ct <= rules['acceptable_max_words']:\n",
    "        length_pts = 25\n",
    "    elif 0 < word_ct < rules['acceptable_min_words']:\n",
    "        length_pts = 10 # Too Short (but not empty)\n",
    "    \n",
    "    # 2. Bullet structure (0–30 pts)\n",
    "    bullets_pts = 0\n",
    "    bullet_count = 0\n",
    "    try:\n",
    "        bullets = json.loads(bullets_json)\n",
    "        bullet_count = len(bullets) if isinstance(bullets, list) else 0\n",
    "        if bullet_count >= 8:\n",
    "            bullets_pts = 30\n",
    "        elif bullet_count >= 5:\n",
    "            bullets_pts = 25\n",
    "        elif bullet_count >= 2:\n",
    "            bullets_pts = 15\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "        \n",
    "    # 3. Benefit language (0–30 pts)\n",
    "    benefit_pts = 0\n",
    "    matched_benefits = set()\n",
    "    normalized_desc = clean_and_normalize(description_text)\n",
    "    for verb in BENEFIT_VERBS:\n",
    "        if verb in normalized_desc:\n",
    "            matched_benefits.add(verb)\n",
    "            \n",
    "    distinct_benefit_count = len(matched_benefits)\n",
    "    if distinct_benefit_count >= 5:\n",
    "        benefit_pts = 30\n",
    "    elif distinct_benefit_count >= 3:\n",
    "        benefit_pts = 25\n",
    "    elif distinct_benefit_count >= 1:\n",
    "        benefit_pts = 15\n",
    "        \n",
    "    descscore = min(100, length_pts + bullets_pts + benefit_pts)\n",
    "    \n",
    "    # Diagnostics\n",
    "    diag = {\n",
    "        'desc_word_count': word_ct,\n",
    "        'desc_bullets_count': bullet_count, # Internal diagnostic\n",
    "        'desc_benefits_count': distinct_benefit_count, # Internal diagnostic\n",
    "    }\n",
    "    \n",
    "    return descscore, diag\n",
    "\n",
    "print(\"Cell 5: Description Score logic defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a2ead9d-2ae2-4c5b-9124-ea701909b9b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# CELL 6: Dimension 3: Image Score Logic (imagescore)\n",
    "# Measures image count compliance against retailer expectations and variety proxy.\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "def score_images(image_count, retailer_key):\n",
    "    \"\"\"Dimension 3: Image Score (imagescore)\"\"\"\n",
    "    \n",
    "    # 1. Image count (0–70 pts)\n",
    "    count_pts = 0\n",
    "    \n",
    "    if retailer_key == 'amazon':\n",
    "        if image_count >= 6: count_pts = 70\n",
    "        elif image_count >= 4: count_pts = 55\n",
    "        elif image_count >= 2: count_pts = 35\n",
    "    \n",
    "    elif retailer_key == 'walmart':\n",
    "        if image_count >= 4: count_pts = 70\n",
    "        elif image_count == 3: count_pts = 55\n",
    "        elif image_count == 2: count_pts = 35\n",
    "\n",
    "    elif retailer_key == 'target':\n",
    "        if image_count >= 4 and image_count <= 6: count_pts = 70\n",
    "        elif image_count == 3: count_pts = 55 \n",
    "        elif image_count == 2: count_pts = 35\n",
    "    \n",
    "    # 2. Variety proxy (0–30 pts)\n",
    "    variety_pts = 0\n",
    "    if image_count >= 4:\n",
    "        variety_pts = 30\n",
    "    elif image_count == 3:\n",
    "        variety_pts = 20\n",
    "    elif image_count == 2:\n",
    "        variety_pts = 10\n",
    "        \n",
    "    imagescore = min(100, count_pts + variety_pts)\n",
    "    \n",
    "    # Diagnostics\n",
    "    diag = {'image_count': image_count}\n",
    "    \n",
    "    return imagescore, diag\n",
    "\n",
    "print(\"Cell 6: Image Score logic defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bd033e5-5af1-48c0-b6aa-178b979a5d00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# CELL 7: Dimension 4: Keyword Score Logic (keywordscore)\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "def score_keywords(title_text, description_text, bullets_json, category, retailer_key):\n",
    "    \"\"\"Dimension 4: Keyword Score (keywordscore)\"\"\"\n",
    "    \n",
    "    # FIX: Concatenate the category tuple with the retailer_key to form a flat 3-item tuple key\n",
    "    if category and retailer_key:\n",
    "        lookup_key = category + (retailer_key,)\n",
    "    else:\n",
    "        lookup_key = None\n",
    "        \n",
    "    target_keywords = CATEGORY_KEYWORDS.get(lookup_key)\n",
    "    \n",
    "    if not target_keywords:\n",
    "        return 0, {'keyword_coverage_pct': 0.0, 'matched_keywords': 0}\n",
    "        \n",
    "    # Combine content\n",
    "    combined_content = [title_text, description_text]\n",
    "    try:\n",
    "        bullets = json.loads(bullets_json)\n",
    "        if isinstance(bullets, list):\n",
    "            combined_content.extend(bullets)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    searchable_string = clean_and_normalize(\" \".join(filter(None, combined_content)))\n",
    "    \n",
    "    # Count matches\n",
    "    total_target = len(target_keywords)\n",
    "    matched_keywords = set()\n",
    "    \n",
    "    for keyword in target_keywords:\n",
    "        # FIX: Normalize the individual target keyword before checking against the content.\n",
    "        normalized_keyword = clean_and_normalize(keyword)\n",
    "        \n",
    "        if normalized_keyword and normalized_keyword in searchable_string:\n",
    "            matched_keywords.add(keyword)\n",
    "            \n",
    "    matched_count = len(matched_keywords)\n",
    "    coverage_pct = (matched_count / total_target) * 100\n",
    "    \n",
    "    # Map to score\n",
    "    if coverage_pct >= 80:\n",
    "        keywordscore = 100\n",
    "    elif coverage_pct >= 60:\n",
    "        keywordscore = 75\n",
    "    elif coverage_pct >= 40:\n",
    "        keywordscore = 50\n",
    "    elif coverage_pct >= 20:\n",
    "        keywordscore = 30\n",
    "    else:\n",
    "        keywordscore = 10\n",
    "        \n",
    "    # Diagnostics\n",
    "    diag = {\n",
    "        'keyword_coverage_pct': round(coverage_pct, 1),\n",
    "        'matched_keywords': matched_count # Internal diagnostic\n",
    "    }\n",
    "    \n",
    "    return keywordscore, diag\n",
    "\n",
    "print(\"Cell 7: Keyword Score logic defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08c8d9e3-56be-4c07-8e8a-8252b0031460",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# CELL 8: Dimensions 5 & 6: Rating and Review Score Logic (ratingscore, reviewscore)\n",
    "# Measures customer satisfaction (rating) and social proof (review volume/recency).\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "def score_rating(avg_rating):\n",
    "    \"\"\"Dimension 5: Rating Score (ratingscore)\"\"\"\n",
    "    if avg_rating is None:\n",
    "        return 0, {}\n",
    "\n",
    "    raw_score = (avg_rating / 5.0) * 100\n",
    "\n",
    "    if avg_rating >= 4.5:\n",
    "        bucketed_score = raw_score \n",
    "    elif avg_rating >= 4.0:\n",
    "        range_0_1 = (avg_rating - 4.0) / 0.4\n",
    "        bucketed_score = 80 + (range_0_1 * 9)\n",
    "    elif avg_rating >= 3.1:\n",
    "        range_0_1 = (avg_rating - 3.1) / 0.8\n",
    "        bucketed_score = 60 + (range_0_1 * 19)\n",
    "    else: # 0.0 - 3.0\n",
    "        bucketed_score = min(raw_score, 60)\n",
    "        \n",
    "    ratingscore = round(bucketed_score)\n",
    "    \n",
    "    return ratingscore, {}\n",
    "\n",
    "def score_reviews(review_count, prior_month_review_count):\n",
    "    \"\"\"Dimension 6: Review Score (reviewscore)\"\"\"\n",
    "    \n",
    "    # 1. Volume (0–80 pts)\n",
    "    volume_pts = 0\n",
    "    if review_count >= 200:\n",
    "        volume_pts = 80\n",
    "    elif review_count >= 50:\n",
    "        volume_pts = 60\n",
    "    elif review_count >= 10:\n",
    "        volume_pts = 30\n",
    "    elif review_count > 0:\n",
    "        volume_pts = 10\n",
    "        \n",
    "    # 2. Recency / momentum (0–20 pts)\n",
    "    recency_pts = 10 # Default\n",
    "    if prior_month_review_count is not None:\n",
    "        if review_count >= prior_month_review_count * 1.10:\n",
    "            recency_pts = 20 # 10%+ growth\n",
    "        elif review_count < prior_month_review_count * 0.90:\n",
    "            recency_pts = 0 # Declining\n",
    "        \n",
    "    reviewscore = min(100, volume_pts + recency_pts)\n",
    "    \n",
    "    return reviewscore, {'prior_month_review_count': prior_month_review_count} # Internal diagnostic\n",
    "\n",
    "print(\"Cell 8: Rating and Review Score logic defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37839336-2752-4157-889d-08d953eaf68c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# CELL 9: Overall Scoring Engine and Validation (Updated Lookups)\n",
    "# Combines all subscores into the weighted contentscore and runs the test data.\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "def calculate_content_score(product_content, performance_data, brand_name, category):\n",
    "    \"\"\"\n",
    "    Core engine to calculate all 7 dimension scores and overall Content Score.\n",
    "    \"\"\"\n",
    "    retailer_key = product_content['retailer_key']\n",
    "    \n",
    "    # Initialize master results dictionary\n",
    "    results = {\n",
    "        'product_key': product_content['product_key'],\n",
    "        'retailer_key': retailer_key,\n",
    "        'titlescore': 0, 'descscore': 0, 'imagescore': 0, \n",
    "        'keywordscore': 0, 'ratingscore': 0, 'reviewscore': 0, \n",
    "        'contentscore': 0, \n",
    "        'title_length': 0, 'desc_word_count': 0, 'image_count': 0, \n",
    "        'keyword_coverage_pct': 0.0, 'missing_attributes_list': \"\"\n",
    "    }\n",
    "    \n",
    "    # Execute Dimension Scoring\n",
    "    ts, ts_diag = score_title(product_content['title_text'], retailer_key, brand_name, category, product_content['attributes_json'])\n",
    "    results['titlescore'] = ts\n",
    "    results.update(ts_diag)\n",
    "    \n",
    "    ds, ds_diag = score_description(product_content['description_text'], product_content['bullets_json'], retailer_key)\n",
    "    results['descscore'] = ds\n",
    "    results.update(ds_diag)\n",
    "    \n",
    "    iscore, is_diag = score_images(product_content['image_count'], retailer_key)\n",
    "    results['imagescore'] = iscore\n",
    "    results.update(is_diag)\n",
    "    \n",
    "    ks, ks_diag = score_keywords(product_content['title_text'], product_content['description_text'], product_content['bullets_json'], category, retailer_key)\n",
    "    results['keywordscore'] = ks\n",
    "    results.update(ks_diag)\n",
    "    \n",
    "    rs, _ = score_rating(performance_data.get('avg_rating'))\n",
    "    results['ratingscore'] = rs\n",
    "    \n",
    "    revs, revs_diag = score_reviews(performance_data.get('review_count', 0), performance_data.get('prior_month_review_count'))\n",
    "    results['reviewscore'] = revs\n",
    "    \n",
    "    # D7: Overall Content Score (contentscore) - Weighted Average\n",
    "    contentscore = round(\n",
    "        0.25 * results['titlescore'] + \n",
    "        0.20 * results['descscore'] + \n",
    "        0.20 * results['imagescore'] + \n",
    "        0.15 * results['keywordscore'] + \n",
    "        0.10 * results['ratingscore'] + \n",
    "        0.10 * results['reviewscore']\n",
    "    )\n",
    "    results['contentscore'] = contentscore\n",
    "    \n",
    "    # Clean up diagnostics for final output table\n",
    "    final_results = {k: v for k, v in results.items() if k not in ['title_length_pts', 'title_brand_pts', 'title_category_pts', 'title_attribute_pts', 'desc_bullets_count', 'desc_benefits_count', 'prior_month_review_count', 'matched_keywords']}\n",
    "    \n",
    "    return final_results\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Output Table Schema Definition and Name\n",
    "# ------------------------------------------------------\n",
    "\n",
    "OUTPUT_TABLE_NAME = \"skulytics_dev.default.product_content_scores_tbl\"\n",
    "\n",
    "# Define the schema for the output table\n",
    "OUTPUT_SCHEMA = StructType([\n",
    "    StructField(\"product_key\", StringType(), False),\n",
    "    StructField(\"retailer_key\", StringType(), False),\n",
    "    StructField(\"datekey\", StringType(), False),\n",
    "    StructField(\"titlescore\", IntegerType(), False),\n",
    "    StructField(\"descscore\", IntegerType(), False),\n",
    "    StructField(\"imagescore\", IntegerType(), False),\n",
    "    StructField(\"keywordscore\", IntegerType(), False),\n",
    "    StructField(\"ratingscore\", IntegerType(), False),\n",
    "    StructField(\"reviewscore\", IntegerType(), False),\n",
    "    StructField(\"contentscore\", IntegerType(), False),\n",
    "    StructField(\"title_length\", IntegerType(), True),\n",
    "    StructField(\"desc_word_count\", IntegerType(), True),\n",
    "    StructField(\"image_count\", IntegerType(), True),\n",
    "    StructField(\"keyword_coverage_pct\", DoubleType(), True),\n",
    "    StructField(\"missing_attributes_list\", StringType(), True),\n",
    "])\n",
    "\n",
    "\n",
    "def run_validation():\n",
    "    \"\"\"Runs the scoring engine on mock data, prints the results, and writes to a table.\"\"\"\n",
    "    print(\"--- Content Quality Scoring Engine Results ---\")\n",
    "    print(\"--- (Schema: product_content_scores_tbl) ---\\n\")\n",
    "    \n",
    "    all_scores_data = []\n",
    "    \n",
    "    # Get the list of field names in the correct schema order to ensure positional data mapping\n",
    "    schema_field_names = [f.name for f in OUTPUT_SCHEMA.fields]\n",
    "    \n",
    "    # ITERATE OVER THE PRIMARY CONTENT TABLE\n",
    "    for content in MOCK_CONTENT_TBL:\n",
    "        sku = content['product_key']\n",
    "        retailer = content['retailer_key']\n",
    "        \n",
    "        # 1. Lookup Performance Data (simulates JOIN with fact_retail_summary_tbl)\n",
    "        perf_data = next((p for p in MOCK_FACT_RETAIL_SUMMARY_TBL if p['product_key'] == sku and p['retailer_key'] == retailer), {})\n",
    "        \n",
    "        # 2. Lookup Brand Name (simulates JOIN with dim_brand)\n",
    "        brand_name = next((d['brand_name'] for d in MOCK_DIM_BRAND if d['product_key'] == sku), None)\n",
    "        \n",
    "        # 3. Lookup Category Data (simulates JOIN with dim_product)\n",
    "        # Note: Category is passed as a tuple (major, minor)\n",
    "        category_data = next(((d['major'], d['minor']) for d in MOCK_DIM_PRODUCT if d['product_key'] == sku), (None, None))\n",
    "        \n",
    "        # EXECUTE THE CORE SCORING ENGINE\n",
    "        score_data = calculate_content_score(\n",
    "            product_content=content,\n",
    "            performance_data=perf_data,\n",
    "            brand_name=brand_name,\n",
    "            category=category_data\n",
    "        )\n",
    "        \n",
    "        # Add datekey and store results\n",
    "        score_data['datekey'] = '2025-12-01'\n",
    "        all_scores_data.append(score_data)\n",
    "        \n",
    "        # Print results in a readable format (for notebook output)\n",
    "        print(f\"[{sku} @ {retailer.upper()}]\")\n",
    "        print(\"  Subscores:\")\n",
    "        print(f\"    Title Score:    {score_data['titlescore']:>3} (L{score_data.get('title_length_pts', 0)} + B{score_data.get('title_brand_pts', 0)} + C{score_data.get('title_category_pts', 0)} + A{score_data.get('title_attribute_pts', 0)})\")\n",
    "        print(f\"    Description:    {score_data['descscore']:>3}\")\n",
    "        print(f\"    Image Score:    {score_data['imagescore']:>3}\")\n",
    "        print(f\"    Keyword Score:  {score_data['keywordscore']:>3}\")\n",
    "        print(f\"    Rating Score:   {score_data['ratingscore']:>3}\")\n",
    "        print(f\"    Review Score:   {score_data['reviewscore']:>3}\")\n",
    "        print(f\"  --> OVERALL SCORE:  {score_data['contentscore']:>3}\")\n",
    "        print(\"  Diagnostics:\")\n",
    "        print(f\"    Title Length: {score_data['title_length']} chars\")\n",
    "        print(f\"    Desc Word Count: {score_data['desc_word_count']}\")\n",
    "        print(f\"    Image Count: {score_data['image_count']}\")\n",
    "        print(f\"    Keyword Coverage: {score_data['keyword_coverage_pct']}%\")\n",
    "        print(f\"    Missing Attributes: {score_data['missing_attributes_list'] or 'None'}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # NEW LOGIC: Create DataFrame and Write to Table\n",
    "    # ------------------------------------------------------\n",
    "    \n",
    "    if all_scores_data:\n",
    "        print(\"\\n--- Persistence: Writing Results to Databricks Catalog ---\")\n",
    "        \n",
    "        try:\n",
    "            # 1. Convert Python dictionaries to list of values, enforcing schema order\n",
    "            rows_of_values = []\n",
    "            for d in all_scores_data:\n",
    "                # Retrieve values in the exact order of OUTPUT_SCHEMA fields\n",
    "                row_values = [d.get(name) for name in schema_field_names]\n",
    "                rows_of_values.append(row_values)\n",
    "            \n",
    "            # 2. Create Spark DataFrame (using the list of values and the explicit schema)\n",
    "            df_scores = spark.createDataFrame(rows_of_values, schema=OUTPUT_SCHEMA)\n",
    "            \n",
    "            # 3. Write DataFrame to the Delta Table (creating or overwriting it)\n",
    "            df_scores.write \\\n",
    "                .mode(\"overwrite\") \\\n",
    "                .option(\"mergeSchema\", \"true\") \\\n",
    "                .saveAsTable(OUTPUT_TABLE_NAME)\n",
    "                \n",
    "            print(f\"Successfully wrote {len(all_scores_data)} records to table: {OUTPUT_TABLE_NAME}\")\n",
    "            print(f\"You can verify the table content using SQL: SELECT * FROM {OUTPUT_TABLE_NAME}\")\n",
    "            \n",
    "        except NameError:\n",
    "            print(\"ERROR: 'spark' session is not defined. Cannot write to table.\")\n",
    "            print(\"This script is ready for PySpark, but needs to be run inside a connected Databricks cluster.\")\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR during table write: {e}\")\n",
    "\n",
    "    if all_scores_data:\n",
    "        print(\"\\n--- Final Output Table (product_content_scores_tbl) Structure Example ---\")\n",
    "        example_row = all_scores_data[0]\n",
    "        print(json.dumps(example_row, indent=2))\n",
    "        \n",
    "run_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2042028b-eef5-4491-8150-52c63f2f9b18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "select * from skulytics_dev.default.product_content_scores_tbl"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "skulytics_scoring_ticket",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
